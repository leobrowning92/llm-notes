{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring OpenAI API directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import aiohttp\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import llm_notes\n",
    "from pathlib import Path\n",
    "import asyncio\n",
    "import llm_notes\n",
    "import yaml\n",
    "import networkx as nx\n",
    "\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barebones API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'cmpl-7Wixfp28Ij8RcqRvG4wTrYc5y6O1i',\n",
       " 'object': 'text_completion',\n",
       " 'created': 1688033683,\n",
       " 'model': 'text-davinci-003',\n",
       " 'choices': [{'text': '\\n\\nThis is indeed a test.',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 5, 'completion_tokens': 8, 'total_tokens': 13}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {api_key}',\n",
    "}\n",
    "\n",
    "data = {\n",
    "  \"model\": \"text-davinci-003\",\n",
    "  \"prompt\": \"Say this is a test\",\n",
    "  \"max_tokens\": 200,\n",
    "  \"temperature\": 0,\n",
    "}\n",
    "\n",
    "\n",
    "async with aiohttp.ClientSession() as session:\n",
    "    async with session.post(\n",
    "        'https://api.openai.com/v1/completions',\n",
    "        headers=headers,\n",
    "        data=json.dumps(data),\n",
    "    ) as response:\n",
    "        response_data = await response.json()\n",
    "response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-7WixhI75HXYHy1Sf0HqVpysmTPEFr',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1688033685,\n",
       " 'model': 'gpt-3.5-turbo-0613',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant', 'content': 'This is a test.'},\n",
       "   'finish_reason': 'stop'}],\n",
       " 'usage': {'prompt_tokens': 12, 'completion_tokens': 5, 'total_tokens': 17}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer {api_key}',\n",
    "}\n",
    "\n",
    "data = {\n",
    "  \"model\": \"gpt-3.5-turbo\",\n",
    "  \"messages\": [{\"role\":\"user\",\"content\":\"Say this is a test\"}],\n",
    "  \"max_tokens\": 20,\n",
    "  \"temperature\": 0,\n",
    "}\n",
    "\n",
    "\n",
    "async with aiohttp.ClientSession() as session:\n",
    "    async with session.post(\n",
    "        'https://api.openai.com/v1/chat/completions',\n",
    "        headers=headers,\n",
    "        data=json.dumps(data),\n",
    "    ) as response:\n",
    "        response_data = await response.json()\n",
    "response_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def simple_tagger(text, possible_tags, **kwargs):\n",
    "\n",
    "    # Set up the prompt with input variables for tools, user input and a scratchpad for the model to record its workings\n",
    "    template = \"\"\"Tag the given text with tags from the possible tags.\n",
    "\n",
    "    Possible Tags:\n",
    "    {possible_tags}\n",
    "\n",
    "    Return only the most relevant tags, in order of relevance.\n",
    "    Return at most 3 tags, but fewer if there are fewer than 3 relevant tags.\n",
    "\n",
    "\n",
    "    Return answers in the following format:\n",
    "    [tag1, tag2, tag3]\n",
    "\n",
    "    if no tags are found, return an empty list \n",
    "    []\n",
    "    \n",
    "    Text will be delivered in the following format:\n",
    "    Text: 'Example text to be tagged'\n",
    "    \n",
    "    Answer with only the list of tags or an empty list\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Authorization': f'Bearer {api_key}',\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"messages\": [\n",
    "        {\"role\":\"user\",\"content\":template.format(possible_tags=possible_tags)},\n",
    "        {\"role\":\"user\",\"content\":text}\n",
    "    ],\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0,\n",
    "    }\n",
    "    data.update(kwargs)\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(\n",
    "            'https://api.openai.com/v1/chat/completions',\n",
    "            headers=headers,\n",
    "            data=json.dumps(data),\n",
    "        ) as response:\n",
    "            response_data = await response.json()\n",
    "    # print(response_data)\n",
    "    response_text = response_data[\"choices\"][0][\"message\"][\"content\"]\n",
    "    tags = [] if response_text == \"[]\" else re.sub(\"\\[|\\]|'|\\\"\", \"\", response_text).split(\", \")\n",
    "    return tags\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a table of the ways that a simple zero shot classification can be improved based on:\n",
    "Large Language Models in the Workplac - A Case Study on Prompt Engineering for Job Type Classification\n",
    "\n",
    "| Name | Description |\n",
    "| --- | --- |\n",
    "| Baseline | Provide a a job posting and asking if it is fit for a graduate. |\n",
    "| CoT | Give a few examples of accurate classification before querying. |\n",
    "| Zero-CoT | Ask the model to reason step-by-step before providing its answer. |\n",
    "| rawinst | Give instructions about its role and the task by adding to the user msg. |\n",
    "| sysinst | Give instructions about its role and the task as a system msg. |\n",
    "| bothinst | Split instructions with role as a system msg and task as a user msg. |\n",
    "| mock | Give task instructions by mocking a discussion where it acknowledges them. |\n",
    "| reit | Reinforce key elements in the instructions by repeating them. |\n",
    "| strict | Ask the model to answer by strictly following a given template. |\n",
    "| loose | Ask for just the final answer to be given following a given template. |\n",
    "| right | Asking the model to reach the right conclusion. |\n",
    "| info | Provide additional information to address common reasoning failures. |\n",
    "| name | Give the model a name by which we refer to it in conversation. |\n",
    "| pos | Provide the model with positive feedback before querying it. |\n",
    "\n",
    "\n",
    "Their **best prompt** which is Baseline  + bothinst + mock + reit + right + info + name+pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['animals']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await simple_tagger(\"My dog is a good boy\", [\"cooking\", \"animals\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up note collection and graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = llm_notes.note.load_note_directory(Path(\"./example_notes/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.title='relational note taking.md', self.tags=['notetaking'], self.sources=['https://thesephist.com/posts/inc/']\n"
     ]
    }
   ],
   "source": [
    "n = notes[3]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NoteMetadata(title='relational note taking.md',\n",
      "             tags=['#notetaking'],\n",
      "             note_links=['My Note taking principles',\n",
      "                         'Zettelkasten',\n",
      "                         'Evergreen Notes',\n",
      "                         'My Note taking principles',\n",
      "                         'General Zettelkasten Principles',\n",
      "                         'Evergreen Notes',\n",
      "                         'Obsidian',\n",
      "                         'Roam research',\n",
      "                         'Notion'],\n",
      "             back_links=None,\n",
      "             short_title='rltnl_note_tkng.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(n.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "note_graph = llm_notes.note.construct_note_graph(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView(('ldd_qstns_dtls.', 'give_vs_take_cnvrs_styls_cnvrs_drknb', 'imprv_thtre_stryt_frmwr', 'rltnl_note_tkng.', 'sktch_imprv_is_wrkng_bckwr_build_lrgr_wrldv', 'obsdn', 'mnngf_spllc_actn_ecnmy', 'story_rspns_plyrs_over_just_chrct_rspns', 'gcn_graph_cnvlt_lyrs.', 'obsdn_wbste_mkdcs', 'what_is_zttlk', 'graph_nrl_ntwrk_(gnn)_intrd', 'gssn_blf_prpgt', 'how_nmss_systm_crts_strs.', 'cntrl_party_fgre_shrd_npc.m', 'gntle_intrd_graph_nrl_ntwrk', 'fctr_graph_used_prbbl_infrn', 'dstl_-_pb.md', 'death_mvs.m', 'chrch_intrr', 'gnn_2020_rvw_into_2021.', 'blnce_btwn_imprv_prior_scene_rlply', 'prprn_imprv_rpgs.', 'rtls_play', 'frtfl_void_-_rich_never_exhst_dtl', 'ldd_qstns_cmbt', 'ldd_qstns_chrct_crtn', 'swrds_wtht_mstr', 'ldd_qstns_dtls', 'ldd_sttmn_dtls', 'prprn_imprv_rpgs', 'how_nmss_systm_crts_strs', 'my_note_tkng_prncp', 'zttlk', 'evrgr_notes', 'gnrl_zttlk_prncp', 'roam_rsrch', 'ntn', 'mchnc_allow_mnngf_agncy_rpgs', 'osr', 'great_mgcs_rqre_scrfc', 'doubt_advnt_crvs_arln', 'grgna_mines_dwly', 'heart_rpg', 'ant-c_uvg', 'blngn_otsde_blngn_bob_systm', 'mkdcs', 'zttlk_site_frms', 'gcn_graph_cnvlt_lyrs', 'mssge_pssng_algrt', 'obtnn_grnd_truth_lctn_data', 'bysn_mthds', 'bttle_mddl_earth_-_shdw_war', 'how_build_use_strng_thms_mtfs', 'ldd_estbl_qstns', 'tim_bnckn', 'grge_odnnl', 'king_arthr_arthr_lgnds', 'harry_pttr', 'vntre_rpg', 'crvn_shrd_chrct_uvg', 'dstl_-_pub', 'pyro_-_prbbl_prgrm', 'mchl_nlsn', 'andrj_krpth', 'ysho_bngo', 'ian_gdfll', 'uvg_rpg_-_ultra_vlt_grssl', 'lgcy_life_among_ruins_rpg', 'no_time_die_movie', 'scrt_cstro_negro_small_town_devil_mystr', 'last_ghasp_town_gnrtr_wlcme_scnc_whrvr', 'last_ghasp_grmre', 'npc_trngl', 'rkhll_rpg', 'sggst_undrl_chsvn_prcdr_cntnt', 'how_make_bttr_npcs'))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_graph.nodes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = set([])\n",
    "for n in notes:\n",
    "    all_tags.update(n.tags)\n",
    "\n",
    "all_tags = {\n",
    " 'bayesian',\n",
    " 'cite_note',\n",
    " 'deeplearning',\n",
    " 'gamedesign',\n",
    " 'graph',\n",
    " 'homebrew',\n",
    " 'list',\n",
    " 'mythoughts',\n",
    " 'notetaking',\n",
    " 'pbta',\n",
    " 'pluginrules',\n",
    " 'probability',\n",
    " 'resource',\n",
    " 'review',\n",
    " 'rpgs',\n",
    " 'rules',\n",
    " 'stub',\n",
    " 'thoughtcollection',\n",
    " 'thoughts',\n",
    " 'tool',\n",
    " 'tutorial',\n",
    " 'writing'\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['notetaking', 'thoughtcollection', 'mythoughts'] ['notetaking']\n"
     ]
    }
   ],
   "source": [
    "print(await simple_tagger(n.body, all_tags), n.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pred_tags \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mgather(\u001b[39m*\u001b[39m[simple_tagger(n\u001b[39m.\u001b[39mbody, [\u001b[39m\"\u001b[39m\u001b[39mrpgs\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m notes])\n",
      "Cell \u001b[0;32mIn[6], line 48\u001b[0m, in \u001b[0;36msimple_tagger\u001b[0;34m(text, possible_tags, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         response_data \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n\u001b[1;32m     47\u001b[0m \u001b[39m# print(response_data)\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m response_text \u001b[39m=\u001b[39m response_data[\u001b[39m\"\u001b[39;49m\u001b[39mchoices\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     49\u001b[0m tags \u001b[39m=\u001b[39m [] \u001b[39mif\u001b[39;00m response_text \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m[]\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m re\u001b[39m.\u001b[39msub(\u001b[39m\"\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m[|\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m]|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m, response_text)\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m tags\n",
      "\u001b[0;31mKeyError\u001b[0m: 'choices'"
     ]
    }
   ],
   "source": [
    "pred_tags = await asyncio.gather(*[simple_tagger(n.body, [\"rpgs\"]) for n in notes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Questions with details.md\n",
      "['rpgs'] ['rpgs', 'thoughtcollection', 'pbta']\n",
      "give vs take conversation styles and conversational doorknobs.md\n",
      "['rpgs'] []\n",
      "improv theatre as a storytelling framework.md\n",
      "['rpgs'] ['list']\n",
      "relational note taking.md\n",
      "['note taking', 'incremental note taking', 'time'] ['notetaking']\n",
      "Sketch improv is working backward to build a larger worldview.md\n",
      "['rpgs'] ['rpg']\n",
      "Obsidian.md\n",
      "[] ['notetaking', 'tool']\n",
      "meaningful spellcasting and the action economy.md\n",
      "['rpgs'] ['rpg', 'thoughts']\n",
      "Story responsibility for players over just Character responsibility.md\n",
      "['rpgs'] ['rpg', 'thoughtcollection', 'pbta', 'ksbd', 'swordswithoutmaster']\n",
      "GCN graph convolution layers.md\n",
      "[] []\n",
      "obsidian website with mkdocs.md\n",
      "['rpgs'] ['writing', 'tutorial']\n",
      "What is zettelkasten.md\n",
      "['zettelkasten', 'Niklas Luhmann', 'systems theory'] ['thoughtcollection', 'notetaking', 'cite_note', 'cite_note', 'cite_note', 'cite_note']\n",
      "Graph neural network (GNN) Introduction.md\n",
      "['message passing algorithm', 'GCN graph convolution layers', 'Obtaining ground truth location data'] ['deeplearning', 'graph']\n",
      "Gaussian belief propagation.md\n",
      "['rpgs'] ['bayesian', 'graph', 'probability']\n",
      "How the Nemesis system creates stories.md\n",
      "['rpgs'] ['gamedesign', 'review']\n",
      "central party figure as a shared npc.md\n",
      "['rpgs'] []\n",
      "A Gentle Introduction to Graph Neural Networks.md\n",
      "['message passing algorithm', 'Graph neural network (GNN) Introduction', 'rpgs'] ['graph', 'deeplearning']\n",
      "factor graph used for prababilistic inference.md\n",
      "[] ['probability']\n",
      "distil - pub.md\n",
      "['rpgs'] ['deeplearning', 'resource']\n",
      "Death Moves.md\n",
      "['rpgs'] ['rpg', 'homebrew', 'rules', 'pluginrules']\n",
      "The Church of Interruption.md\n",
      "['rpgs'] []\n",
      "GNN 2020 review and into 2021.md\n",
      "['rpgs'] ['graph', 'deeplearning', 'stub']\n",
      "Balance between improv and prior scene in roleplay.md\n",
      "['rpgs'] ['rpg', 'anticannon', 'improv']\n",
      "Preparing to improv in rpgs.md\n",
      "['rpgs'] ['mythoughts', 'thoughtcollection', 'rpg']\n"
     ]
    }
   ],
   "source": [
    "for pt, n in zip(pred_tags, notes):\n",
    "    print(n.title)\n",
    "    print(pt, n.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.title='Balance between improv and prior scene in roleplay.md', self.tags=['rpg', 'anticannon', 'improv'], self.sources=[]\n"
     ]
    }
   ],
   "source": [
    "print(notes[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[[Sketch improv is working backward to build a larger worldview]], starting with a detail framed with open ended connection to other unknown details. In improv you take that as writ, and then continue to flesh out and build on those connections. The process of doing this backwards is that you build scene from successively widening the lens for details. A cohesive scene is thus emergent rather than prescriptive where the details would come out of a broad framing.\n",
      "\n",
      "In an rpg things are a little bit more flexible, in that we can, and often want to, spend some more time before hand to build details. We can also change details after the fact (retcon) to better suit a new idea or narrative as we see it evolving.\n",
      "\n",
      "I should say ideally, because if we are to attached to things that are already established, then we cant be free with where things are going. And if we are too attached to where things are going, then we might have to run roughshod over what has been established. See [[The secret of Castro negro small town devil mystery]] for a good discussion of how to strike the balance of hitting repeat themes and motifs while still being flexible. This balance between future creativity, and the richness of past narrative is a balance I think is well discussed by the idea of [[anti-cannon in the UVG]]\n",
      "\n",
      "Seth Rogen said of what makes good improv [in this interview](https://www.youtube.com/watch?v=vxIfm_olRz0) that the best improve comes from thinking like a writer not an actor. Of thinking not just what would my character would say in this moment, but what would I hope a character would say to make this whole scene better and move the story forward and make it all seem more natural and round out the edges that dialogue can have sometime.\n"
     ]
    }
   ],
   "source": [
    "print(notes[-2].body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metadata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m---\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m----> 3\u001b[0m     yaml\u001b[39m.\u001b[39mdump(metadata),\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m---\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(n\u001b[39m.\u001b[39mlines),\n\u001b[1;32m      6\u001b[0m ]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metadata' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"\".join([\n",
    "    \"---\\n\",\n",
    "    yaml.dump(metadata),\n",
    "    \"---\\n\\n\",\n",
    "    \"\\n\".join(n.lines),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relational note taking.md\n",
      "- source: https://thesephist.com/posts/inc/\n",
      "- tags: #notetaking \n",
      "Blog post codefying their note taking style, principles and tooling. informs much of [[My Note taking principles]].\n",
      "\n",
      "Uses an iceberg analogy, where most note taking accounts for the 10% of structured, easily codefiable notes such as meeting or lecture notes, or notes from reading. But misses the 90% of thoughts that are the majority of our thought process.\n",
      "\n",
      "Has a strong emphasis on the incremental nature of thought, and the nature of notes over time. My own past positive experience with note taking, and using those notes, was a chronological pen-and-paper lab notebook. a chronological view, with some labeling to spur thought, was the most effective way in which I actually used and referred back to my notes. This was acheived with a paper note taking system, which in this blog they discuss as being a low barrier way to capture the 90% of thought in their iceberg analogy.\n",
      "\n",
      "Things like [[Zettelkasten]] and [[Evergreen Notes]] focus on relational note organisation, and IMO their emphasis on time is taking a closer look at one of the only universal, in built, relationships that we share as people taking notes.\n",
      "\n",
      "\n",
      "\n",
      "They state the following principles for incremental note taking:\n",
      "> 1.  **Captured ideas are better than missed ones.** They go on to strongly emphasise low barrier to thought capture.\n",
      "> 2.  **Adding new ideas is better than updating old ones.** Preserves process, and is non-lossy.\n",
      "> 3.  **Ideas that can’t be recalled are worse than useless** – effective search and recall form the soul of great notes. Regardless of how you recall information back from your notes, a great note-taking system should make it trivial to get ideas out, as well as in.\n",
      "> 4.  **Time is essential to how we remember**, and should be a first-class concept in a good note-taking system.\n",
      "\n",
      "The way that this article describe them is a good example for [[My Note taking principles]]\n",
      "\n",
      "Of these, only the last one is not compatible with or doesn't overlap with [[General Zettelkasten Principles]] or [[Evergreen Notes]].\n",
      "\n",
      "His primary critique of tools such as [[Obsidian]], [[Roam research]], or [[Notion]] is the lack of a first class way to look at things over time.\n"
     ]
    }
   ],
   "source": [
    "print(n.title)\n",
    "print(n.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
