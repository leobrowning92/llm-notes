{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader, UnstructuredMarkdownLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chat_llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\", callbacks=[StdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<langchain.callbacks.stdout.StdOutCallbackHandler at 0x1381d0b10>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWhat would be a good company name for a company that makes colorful shoes?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nRainbow Footwear.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## running by constructing a chain, prompt and template explicityl\n",
    "llm = OpenAI(temperature=0.9, model=\"text-davinci-003\", verbose=True)\n",
    "handler = StdOutCallbackHandler()\n",
    "prompt = PromptTemplate.from_template(\"What would be a good company name for a company that makes colorful {item}?\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt, callbacks=[handler])\n",
    "chain.run(item=\"shoes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='VibrantSox \\n\\nColorPopSocks \\n\\nRainbowThread \\n\\nSockSpectrum \\n\\nChromaSocks \\n\\nColorBlendCo \\n\\nHueHosiery \\n\\nChromaticSocks \\n\\nColorCraze \\n\\nTintedToes \\n\\nChromaToeCo \\n\\nColorSplashSocks \\n\\nVividVibeSocks \\n\\nRainbowStitch \\n\\nSockSwatch \\n\\nSpectrumThreads \\n\\nChromaWeave \\n\\nColorFeverSockCo \\n\\nHueHabit \\n\\nVibrantVoyageSocks' additional_kwargs={} example=False\n"
     ]
    }
   ],
   "source": [
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "print(chat_llm([HumanMessage(content=text)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='tags: #graph #deeplearning\\n\\nfrom [[distil - pub]].\\n\\nAn excellent resource for a technically skilled, but not necessarily knowledgeable, practitioner. This assumes some understanding of deep learning more broadly, and a cursory understanding of graphs, but quickly ramps up to an overview suitable for an ML practitioner.\\n\\nand relates to [[Graph neural network (GNN) Introduction]] which tends to focus on the GCN layers specifically and sampling from a graph, which is also discussed here.\\n\\nThey emphasise how a [[message passing algorithm]] is used to pass embeddings via the connectivity of the graph to give nodes and edges near it, k-hops away, where the number of layers is the number of hops. these messages are then aggregated together, and then passed through a learned update function to update the node or edge.\\n\\nmessage passing can occur from edges to edges via node connections and nodes to nodes via edge connections.\\n\\nThere can also be a learned linear mapping from nodes to edges, where you want that information to flow from node to edge or edge to node. This is especially important if your dataset includes node information, and you want to predict on edges or vise versa.\\n\\nA cool insight is to have a master node which is connected to all nodes and allows passing of global context.\\n\\nThey also stress that much of the work is in structuring the graphs sensibly, for example multi-partite graphs with different structures between different node or edge types, or nested graphs.', metadata={'source': 'example_notes/A Gentle Introduction to Graph Neural Networks.md'})]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UnstructuredMarkdownLoader(\"example_notes/A Gentle Introduction to Graph Neural Networks.md\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 139.63it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loader = DirectoryLoader('example_notes/', loader_cls=UnstructuredMarkdownLoader, show_progress=True)\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'example_notes/Loaded Questions with details.md'),\n",
       " (1,\n",
       "  'example_notes/give vs take conversation styles and conversational doorknobs.md'),\n",
       " (2, 'example_notes/improv theatre as a storytelling framework.md'),\n",
       " (3, 'example_notes/relational note taking.md'),\n",
       " (4,\n",
       "  'example_notes/Sketch improv is working backward to build a larger worldview.md'),\n",
       " (5, 'example_notes/Obsidian.md'),\n",
       " (6, 'example_notes/meaningful spellcasting and the action economy.md'),\n",
       " (7,\n",
       "  'example_notes/Story responsibility for players over just Character responsibility.md'),\n",
       " (8, 'example_notes/GCN graph convolution layers.md'),\n",
       " (9, 'example_notes/obsidian website with mkdocs.md'),\n",
       " (10, 'example_notes/What is zettelkasten.md'),\n",
       " (11, 'example_notes/Graph neural network (GNN) Introduction.md'),\n",
       " (12, 'example_notes/Gaussian belief propagation.md'),\n",
       " (13, 'example_notes/How the Nemesis system creates stories.md'),\n",
       " (14, 'example_notes/central party figure as a shared npc.md'),\n",
       " (15, 'example_notes/A Gentle Introduction to Graph Neural Networks.md'),\n",
       " (16, 'example_notes/factor graph used for prababilistic inference.md'),\n",
       " (17, 'example_notes/distil - pub.md'),\n",
       " (18, 'example_notes/Death Moves.md'),\n",
       " (19, 'example_notes/The Church of Interruption.md'),\n",
       " (20, 'example_notes/GNN 2020 review and into 2021.md'),\n",
       " (21, 'example_notes/Balance between improv and prior scene in roleplay.md'),\n",
       " (22, 'example_notes/Preparing to improv in rpgs.md')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(i,d.metadata[\"source\"]) for i,d in enumerate(docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='blog on GCN more specifically', metadata={'source': 'example_notes/GCN graph convolution layers.md'})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What did the president say about Ketanji Brown Jackson',\n",
       " 'answer': 'The president did not mention Ketanji Brown Jackson.\\nSOURCES:',\n",
       " 'sources': ''}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "\n",
    "\n",
    "db = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "qa = RetrievalQAWithSourcesChain.from_chain_type(llm=chat_llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "\n",
    "query = \"What did the president say about Ketanji Brown Jackson\"\n",
    "qa(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.faiss.FAISS at 0x1784c1910>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'source': 'example_notes/Graph neural network (GNN) Introduction.md'},\n",
       "  'tags: #apple\\n\\nsource: from twitter list primary blog \\nsee [[GCN graph convolution layers]]\\n\\nOverview\\n\\nGraph neural networks essentially use weighted [[message passing algorithm]] by multiplying the node features X, the normalised adjacency matrix (or some Linear Diffusion operator) A, and a learned weight matrix W.\\n\\nSo each layer in the simple GCN would be ReLU(AXW).  However, for a deep network that requires the Adjacency matrix stored in memory, which is prohibitive for large networks. Multiple layers allow information to be passed through the network. Additionally initial work used sampling, SGD, and mini batches, but using the nodes in a graph as samples ignores the fact that they are not independent points from some distribution. More sophisticated deep networks sample subgraphs or L-hop (L = layer number) graphs to reduce the computational load, and address the dependance of samples.'),\n",
       " ({'source': 'example_notes/Graph neural network (GNN) Introduction.md'},\n",
       "  'However, the core focus of the primary blog post was on the SIGN (Scaleable Inception-like Graph Networks), which instead of deep layers, use a shallow layer that computes many different Diffusion operators (actually powers of the norm Adj matrix to represent n-hops). PyTorch Geometric Implementation Example Shows how simple this pre-computation can be, to the extent that you are simply writing a parallel linear and concatenation followed by a MLP. This is key, as it lets you define whatever kind of output feature you want to train on, for example (n,f) for node level, or (1,f) for graph level.\\n\\nThoughts\\n\\nIm not sure at the moment how that fits for representation learning on graphs, or semi-supervised methods, which I think will be quite important for us.\\n\\nOut lack of real [[Obtaining ground truth location data]] extends to a lack of ground truth data about a graph that we might like to train.\\n\\nAlso need to look into how transfer learning on graphs works.')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(m,d) for d,m in zip(db.get()[\"documents\"], db.get()[\"metadatas\"])  if m[\"source\"]=='example_notes/Graph neural network (GNN) Introduction.md']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'what are the tags appropriate for notes on fruit?',\n",
       " 'answer': 'The appropriate tags for notes on fruit are #apple.\\n',\n",
       " 'sources': 'example_notes/test note.md'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what are the tags appropriate for notes on fruit?\"\n",
    "qa(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'what tags are in the note on Graph neural network (GNN) Introduction that are not appropriate to the content?',\n",
       " 'answer': 'The inappropriate tags in the note on Graph neural network (GNN) Introduction are \"#apple\" and \"#stub\".\\n',\n",
       " 'sources': 'example_notes/Graph neural network (GNN) Introduction.md'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what tags are in the note on Graph neural network (GNN) Introduction that are not appropriate to the content?\"\n",
    "qa(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts so far\n",
    "\n",
    "Seems like this is a case for consuming more of the notes linked to this note \n",
    "then doing some prompt engineering to give the model context sufficient to actually do the task of tagging. Can look into agents/chains for this.\n",
    "\n",
    "Additionally could be useful to look into guidance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
